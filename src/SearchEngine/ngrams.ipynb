{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Running:  (576, 12562)\n",
      "loading data\n",
      "testSchema:  (150511247, 158070149)\n"
     ]
    }
   ],
   "source": [
    "import tracemalloc\n",
    "from queryConstruction import constructQuery\n",
    "import globalVars\n",
    "from ranker import *\n",
    "from clustering import *\n",
    "from searchIndexer import *\n",
    "tracemalloc.start()\n",
    "print(\"Start Running: \",tracemalloc.get_traced_memory())\n",
    "\n",
    "print(\"loading data\")\n",
    "listOfQueries = getListQueries()\n",
    "path = globalVars.path\n",
    "\n",
    "##########load schema###########\n",
    "with open(path+'/TestSchemas/sportsSchema.pickle','rb') as file:\n",
    "    testSchema = pickle.load(file)\n",
    "    \n",
    "print(\"testSchema: \",tracemalloc.get_traced_memory())\n",
    "tracemalloc.stop()\n",
    "\n",
    "tracemalloc.start()\n",
    "###########one hot encoding############\n",
    "globalVars.init()\n",
    "\n",
    "OneHotVocab = globalVars.OneHotVocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosql\n",
      "greatSql\n",
      "nvBench\n",
      "sparc\n",
      "splash\n",
      "topics\n",
      "23\n",
      "127414\n",
      "78849\n",
      "{'query': 'select distinct farealias0.fare_id from airport_service as airport_servicealias0 , airport_service as airport_servicealias1 , city as cityalias0 , city as cityalias1 , days as daysalias0 , days as daysalias1 , days as daysalias2 , days as daysalias3 , days as daysalias4 , days as daysalias5 , days as daysalias6 , days as daysalias7 , days as daysalias8 , days as daysalias9 , fare as farealias0 , fare_basis as fare_basisalias0 , fare_basis as fare_basisalias1 , fare_basis as fare_basisalias2 , fare_basis as fare_basisalias3 , fare_basis as fare_basisalias4 , fare_basis as fare_basisalias5 , flight as flightalias0 , flight_fare as flight_farealias0 where ( ( ( ( ( ( ( ( ( ( daysalias8.day_name = \" day_name0 \" and daysalias9.day_name = \" day_name1 \" and flightalias0.flight_days = daysalias8.days_code and flightalias0.flight_days = daysalias9.days_code ) and daysalias7.day_name = \" day_name2 \" and flightalias0.flight_days = daysalias7.days_code ) and daysalias6.day_name = \" day_name3 \" and flightalias0.flight_days = daysalias6.days_code ) and daysalias5.day_name = \" day_name4 \" and flightalias0.flight_days = daysalias5.days_code ) and cityalias1.city_code = airport_servicealias1.city_code and cityalias1.city_name = \" city_name0 \" and flightalias0.to_airport = airport_servicealias1.airport_code ) and cityalias0.city_code = airport_servicealias0.city_code and cityalias0.city_name = \" city_name1 \" and daysalias4.day_name = \" day_name1 \" and fare_basisalias5.basis_days = daysalias4.days_code and farealias0.fare_basis_code = fare_basisalias5.fare_basis_code and flight_farealias0.fare_id = farealias0.fare_id and flightalias0.flight_id = flight_farealias0.flight_id and flightalias0.from_airport = airport_servicealias0.airport_code ) and daysalias3.day_name = \" day_name0 \" and fare_basisalias4.basis_days = daysalias3.days_code and farealias0.fare_basis_code = fare_basisalias4.fare_basis_code ) and daysalias2.day_name = \" day_name2 \" and fare_basisalias3.basis_days = daysalias2.days_code and farealias0.fare_basis_code = fare_basisalias3.fare_basis_code ) and daysalias1.day_name = \" day_name3 \" and fare_basisalias2.basis_days = daysalias1.days_code and farealias0.fare_basis_code = fare_basisalias2.fare_basis_code ) and daysalias0.day_name = \" day_name4 \" and fare_basisalias1.basis_days = daysalias0.days_code and farealias0.fare_basis_code = fare_basisalias1.fare_basis_code ) and fare_basisalias0.class_type = \" class_type0 \" and farealias0.fare_basis_code = fare_basisalias0.fare_basis_code ;', 'entities': ['airport_service', 'airport_service', 'city', 'city', 'days', 'days', 'days', 'days', 'days', 'days', 'days', 'days', 'days', 'days', 'fare', 'fare_basis', 'fare_basis', 'fare_basis', 'fare_basis', 'fare_basis', 'fare_basis', 'flight', 'flight_fare'], 'selectAttrs': ['fare.fare_id'], 'joinAttrs': [], 'groupByAttrs': [], 'orderByAttrs': [], 'aggrAttrs': [], 'whereAttrs': ['days.day_name', 'days.day_name', 'flight.flight_days', 'days.days_code', 'flight.flight_days', 'days.days_code', 'days.day_name', 'flight.flight_days', 'days.days_code', 'days.day_name', 'flight.flight_days', 'days.days_code', 'days.day_name', 'flight.flight_days', 'days.days_code', 'city.city_code', 'service.airport_city_code', 'city.city_name', 'flight.to_airport', 'service.airport_airport_code', 'city.city_code', 'service.airport_city_code', 'city.city_name', 'days.day_name', 'basis.fare_basis_days', 'days.days_code', 'fare.fare_basis_code', 'basis.fare_fare_basis_code', 'fare.flight_fare_id', 'fare.fare_id', 'flight.flight_id', 'fare.flight_flight_id', 'flight.from_airport', 'service.airport_airport_code', 'days.day_name', 'basis.fare_basis_days', 'days.days_code', 'fare.fare_basis_code', 'basis.fare_fare_basis_code', 'days.day_name', 'basis.fare_basis_days', 'days.days_code', 'fare.fare_basis_code', 'basis.fare_fare_basis_code', 'days.day_name', 'basis.fare_basis_days', 'days.days_code', 'fare.fare_basis_code', 'basis.fare_fare_basis_code', 'days.day_name', 'basis.fare_basis_days', 'days.days_code', 'fare.fare_basis_code', 'basis.fare_fare_basis_code', 'basis.fare_class_type', 'fare.fare_basis_code', 'basis.fare_fare_basis_code']}\n"
     ]
    }
   ],
   "source": [
    "#####get max number of entities in dataset and get total number of unique attributes ###\n",
    "import json\n",
    "datasets = [\"cosql\",\"greatSql\",\"nvBench\",\"sparc\",\"splash\",\"topics\"]\n",
    "maxEntities = 0\n",
    "totalSelectAttrs = 0\n",
    "totalWhereAttrs = 0\n",
    "d = \"\"\n",
    "l = {}\n",
    "for dataset in datasets:\n",
    "    with open('/home/nada/GP/GP/GP/notebooks/preparingDatasets/finalOutputs/'+dataset+'.json', 'r',encoding='UTF-8') as file:\n",
    "        print(dataset)\n",
    "        data = json.load(file)\n",
    "        for query in data:\n",
    "            for q in query[\"allQueries\"]:\n",
    "                totalSelectAttrs = totalSelectAttrs + len(list(set(q[\"selectAttrs\"])))\n",
    "                totalWhereAttrs = totalWhereAttrs + len(list(set(q[\"whereAttrs\"])))\n",
    "                if len(q[\"entities\"]) > maxEntities:\n",
    "                    maxEntities = len(q[\"entities\"])\n",
    "                    l = q\n",
    "\n",
    "\n",
    "print(maxEntities)\n",
    "print(totalSelectAttrs)\n",
    "print(totalWhereAttrs)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-gram => prob of selecting attribute in general\n",
    "# 2-gram => prob of selecting attribute given entity\n",
    "# 3-gram => prob of selecting attribute given 2 entities \n",
    "# and so on .....\n",
    "# max number of entities 12 => 13-gram \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greatSql\n",
      "nvBench\n",
      "sparc\n",
      "splash\n",
      "topics\n"
     ]
    }
   ],
   "source": [
    "#####get unigram (calculating frequencies) for attributes ###\n",
    "import json\n",
    "datasets = [\"cosql\",\"greatSql\",\"nvBench\",\"sparc\",\"splash\",\"topics\"]\n",
    "ngramsDict = {}\n",
    "ngramsDict[\"selectAttrsDict\"] = {}\n",
    "ngramsDict[\"whereAtrrsDict\"] = {}\n",
    "for dataset in datasets:\n",
    "    with open('/home/nada/GP/GP/GP/notebooks/preparingDatasets/finalOutputs/'+dataset+'.json', 'r',encoding='UTF-8') as file:\n",
    "        print(dataset)\n",
    "        data = json.load(file)\n",
    "        for query in data:\n",
    "            for q in query[\"allQueries\"]:\n",
    "                for attr in q[\"selectAttrs\"]:\n",
    "                    if attr.find(\".\") != -1:\n",
    "                        attr = attr.split(\".\")[1]\n",
    "                    attr = attr.split(\"_\")\n",
    "                    attrOneHotVector = (getKeyWordsVector(attr)).tostring()\n",
    "                    if ngramsDict[\"selectAttrsDict\"].get(attrOneHotVector) is None:\n",
    "                        ngramsDict[\"selectAttrsDict\"][attrOneHotVector] = 1\n",
    "                    else:\n",
    "                        ngramsDict[\"selectAttrsDict\"][attrOneHotVector] += 1\n",
    "                for attr in q[\"whereAttrs\"]:\n",
    "                    if attr.find(\".\") != -1:\n",
    "                        attr = attr.split(\".\")[1]\n",
    "                    attr = attr.split(\"_\")\n",
    "                    attrOneHotVector = (getKeyWordsVector(attr)).tostring()\n",
    "                    if ngramsDict[\"whereAtrrsDict\"].get(attrOneHotVector) is None:\n",
    "                        ngramsDict[\"whereAtrrsDict\"][attrOneHotVector] = 1\n",
    "                    else:\n",
    "                        ngramsDict[\"whereAtrrsDict\"][attrOneHotVector] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/home/nihal/Desktop/new_repo/GP/src/SearchEngine/nGrams/0.pickle\", 'wb') as handle:\n",
    "    pickle.dump(ngramsDict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNgramsDict(attributes,name,combinations):\n",
    "    for combination in combinations:\n",
    "        for attr in list(set(attributes)):\n",
    "            if attr.find(\".\") != -1:\n",
    "                attr = attr.split(\".\")[1]\n",
    "            attr = attr.split(\"_\")\n",
    "            attrOneHotVector = (getKeyWordsVector(attr)).tostring()\n",
    "            if nGramsDict[name][np.array(list(combination)).tostring()].get(attrOneHotVector) is None:\n",
    "                nGramsDict[name][np.array(list(combination)).tostring()][attrOneHotVector] = 0\n",
    "            nGramsDict[name][np.array(list(combination)).tostring()][attrOneHotVector] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:31: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  import sys\n",
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  \n",
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  if __name__ == '__main__':\n",
      "/home/nada/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greatSql\n",
      "nvBench\n",
      "sparc\n",
      "splash\n",
      "academic\n",
      "advising\n",
      "geography\n",
      "imdb\n",
      "restaurants\n",
      "scholar\n",
      "spider\n",
      "yelp\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pickle\n",
    "nGramsDict = {}\n",
    "nGramsDict[\"selectAttrsDict\"] = {}\n",
    "nGramsDict[\"whereAtrrsDict\"] = {}\n",
    "datasets = [\"cosql\",\"greatSql\",\"nvBench\",\"sparc\",\"splash\",\"academic\",\"advising\",\"geography\",\"imdb\",\"restaurants\",\"scholar\",\"spider\",\"yelp\"]\n",
    "entitiesProp={}\n",
    "for dataset in datasets:\n",
    "\n",
    "    with open('/home/nada/GP/GP/GP/notebooks/preparingDatasets/finalOutputs/'+dataset+'.json', 'r',encoding='UTF-8') as file:\n",
    "        print(dataset)\n",
    "        data = json.load(file)\n",
    "        for query in data:\n",
    "            for q in query[\"allQueries\"]:\n",
    "                entitiesOneHotVector = []\n",
    "                combinations = []\n",
    "                for entity in list(set(q[\"entities\"])):\n",
    "                    entity = entity.split(\"_\")\n",
    "                    entityOneHotVector = (getKeyWordsVector(entity)).tostring()\n",
    "                    entityKey = np.array(list(entityOneHotVector)).tostring()\n",
    "                    if entitiesProp.get(entityKey) is None:\n",
    "                        entitiesProp[entityKey] = 0\n",
    "                    entitiesProp[entityKey] += 1\n",
    "                    entitiesOneHotVector.append(entityOneHotVector)\n",
    "                for r in range(len(entitiesOneHotVector)+1):\n",
    "                    for combination in itertools.combinations(entitiesOneHotVector, r):\n",
    "                        if len(list(combination)) > 0:\n",
    "                            combinations.append(list(combination))\n",
    "                            nGramsDict[\"selectAttrsDict\"][np.array(list(combination)).tostring()] = {}\n",
    "                            nGramsDict[\"whereAtrrsDict\"][np.array(list(combination)).tostring()] = {}\n",
    "                whereAttributes = [attr[0] for attr in q[\"whereAttrs\"]]\n",
    "                createNgramsDict(q[\"selectAttrs\"],\"selectAttrsDict\",combinations)\n",
    "                createNgramsDict(whereAttributes,\"whereAtrrsDict\",combinations)\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/home/nada/GP/GP/GP/src/SearchEngine/nGrams/ngrams.pickle\", 'wb') as handle:\n",
    "    pickle.dump(nGramsDict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGramsDict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/home/nada/GP/GP/GP/src/SearchEngine/nGrams/entities.pickle\", 'wb') as handle:\n",
    "    pickle.dump(entitiesProp, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "ngramFile = open(\"/home/nada/GP/GP/GP/src/SearchEngine/nGrams/ngrams.pickle\",'rb')\n",
    "nGramsDict = pickle.load(ngramFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
