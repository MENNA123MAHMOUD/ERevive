{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9ca2a6701a14c49af8de80647c71f1770f3d09bf5589e6aad684858921f594a2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from skimage.morphology import (erosion, dilation, opening, closing,  # noqa\n",
    "                                white_tophat)\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import rectangle\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_in = cv2.imread(\"er4.png\", cv2.IMREAD_GRAYSCALE)\n",
    "th, im_th = cv2.threshold(im_in, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "###################Remove words###############\n",
    "structureElm =  np.array((\n",
    "\t[1,1,1],\n",
    "\t[1,1,1]), dtype=\"int\")\n",
    "closed = closing(im_th, structureElm)\n",
    "for i in range(20):\n",
    "    closed = closing(closed, structureElm)\n",
    "cv2.imwrite(\"closed.png\", closed)\n",
    "\n",
    "im2, contours_closed, hierarchy = cv2.findContours(closed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "corners Filled\n"
     ]
    }
   ],
   "source": [
    "# Mask used to flood filling.\n",
    "# Notice the size needs to be 2 pixels than the image.\n",
    "hImg, wImg = im_th.shape[:2]\n",
    "area = hImg*wImg\n",
    "mask = np.zeros((hImg+2, wImg+2), np.uint8)\n",
    "\n",
    "im_floodfill = im_th.copy()\n",
    "##################Flood fill corners#####\n",
    "cv2.floodFill(im_floodfill, mask, (0,0), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (wImg-1,0), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (0,hImg-1), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (wImg-1,hImg-1), 255)\n",
    "\n",
    "print(\"corners Filled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "source": [
    "######################cv contours#########\n",
    "# Invert floodfilled image\n",
    "im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "im2, contours_cv, hierarchy = cv2.findContours(im_floodfill_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "im_empty = np.ones((hImg, wImg,3), np.uint8) * 255\n",
    "cv2.drawContours(im_empty, contours_cv, -1, (0,0,0), 1)\n",
    "cv2.imwrite(\"contoured.png\", im_empty)\n",
    "#########################################\n",
    "# Display images.\n",
    "cv2.imwrite(\"Thresholded_Image.png\", im_th)\n",
    "cv2.imwrite(\"Floodfilled_Image.png\", im_floodfill)\n",
    "cv2.imwrite(\"Inverted_Floodfilled_Image.png\", im_floodfill_inv)\n",
    "#start flooding from corners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValid(imV,m, n, i, j):\n",
    "    #print(i<0 , i>= m , j<0 , j>= n , imV[j][i] == 0)\n",
    "    #print(i,j,m,n)\n",
    "    if (i<0 or i>= m or j<0 or j>= n or imV[j][i] == 0):\n",
    "        return False\n",
    "    return True\n",
    " \n",
    "# FloodFill function\n",
    "def floodFillBFS(screen,m, n, xImg, yImg):\n",
    "    queue = []\n",
    "     \n",
    "    # Append the position of starting\n",
    "    # pixel of the component\n",
    "    queue.append([xImg, yImg])\n",
    " \n",
    "    # Color the pixel with the new color\n",
    "    # if(screen[yImg][xImg]==0):\n",
    "    #     #print(\"hi\")\n",
    "    #     return\n",
    "    screen[yImg][xImg] = 0\n",
    " \n",
    "    # While the queue is not empty i.e. the\n",
    "    # whole component having prevC color\n",
    "    # is not colored with newC color\n",
    "    while queue:\n",
    "        # Dequeue the front node\n",
    "        currPixel = queue.pop() \n",
    "        posX = currPixel[0]\n",
    "        posY = currPixel[1]\n",
    "        # Check if the adjacent\n",
    "        # pixels are valid\n",
    "        if isValid(screen, m, n,posX + 1, posY):\n",
    "           # print(\"valid r\")\n",
    "            screen[posY][posX + 1] = 0\n",
    "            queue.append([posX + 1, posY])\n",
    "         \n",
    "        if isValid(screen, m, n,posX-1, posY):\n",
    "           # print(\"valid l\")\n",
    "            screen[posY][posX-1]= 0\n",
    "            queue.append([posX-1, posY])\n",
    "         \n",
    "        if isValid(screen, m, n, posX, posY + 1):\n",
    "           # print(\"valid d\")\n",
    "            screen[posY + 1][posX]= 0\n",
    "            queue.append([posX, posY + 1])\n",
    "         \n",
    "        if isValid(screen, m, n,posX, posY-1):\n",
    "            #print(\"valid u\")\n",
    "            screen[posY-1][posX]= 0\n",
    "            queue.append([posX, posY-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 196
    }
   ],
   "source": [
    "im_empty_2D=cv2.cvtColor(im_empty,cv2.COLOR_BGR2GRAY) \n",
    "for cnt in contours_closed:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    if w>20 and w<550 and h>5 and h<20:\n",
    "        i = int((2*x+w)/2) \n",
    "        i = i if i>0 else 0\n",
    "        j = y-1 if y>0 else 0\n",
    "        im_empty[j][i] = [0,0,255]\n",
    "        im_empty[y][x] = [0,255,0]\n",
    "        im_empty[y][x+w] = [0,255,0]\n",
    "        im_empty[y+h][x] = [0,255,0]\n",
    "        im_empty[y+h][x+w] = [0,255,0]\n",
    "        floodFillBFS(im_empty_2D,wImg,hImg, i,j)\n",
    "\n",
    "cv2.imwrite(\"contoured.png\", im_empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 197
    }
   ],
   "source": [
    "structureElm =  np.array((\n",
    "\t[1,1,1],\n",
    "\t[1,1,1],\n",
    "    [1,1,1]), dtype=\"int\")\n",
    "im_empty_2D = dilation(im_empty_2D, structureElm)\n",
    "\n",
    "cv2.imwrite(\"flooded.png\", im_empty_2D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}