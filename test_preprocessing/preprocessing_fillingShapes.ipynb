{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9ca2a6701a14c49af8de80647c71f1770f3d09bf5589e6aad684858921f594a2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from skimage.morphology import (erosion, dilation, opening, closing,  # noqa\n",
    "                               white_tophat)\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import rectangle\n",
    "from math import sqrt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 240
    }
   ],
   "source": [
    "im_in = cv2.imread(\"er1.png\", cv2.IMREAD_GRAYSCALE)\n",
    "th, im_th = cv2.threshold(im_in, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "###################Remove words###############\n",
    "structureElm =  np.array((\n",
    "\t[1,1],\n",
    "\t[1,1]), dtype=\"int\")\n",
    "#closed = closing(im_th, structureElm)\n",
    "#for i in range(5):\n",
    "#im_th = closing(im_th, structureElm)\n",
    "cv2.imwrite(\"closed.png\", im_th)\n",
    "\n",
    "#im2, contours_closed, hierarchy = cv2.findContours(closed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "corners Filled\n"
     ]
    }
   ],
   "source": [
    "# Mask used to flood filling.\n",
    "# Notice the size needs to be 2 pixels than the image.\n",
    "hImg, wImg = im_th.shape[:2]\n",
    "area = hImg*wImg\n",
    "mask = np.zeros((hImg+2, wImg+2), np.uint8)\n",
    "\n",
    "im_floodfill = im_th.copy()\n",
    "##################Flood fill corners#####\n",
    "cv2.floodFill(im_floodfill, mask, (0,0), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (wImg-1,0), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (0,hImg-1), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (wImg-1,hImg-1), 255)\n",
    "\n",
    "print(\"corners Filled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5\n0.5555555555555556\n0.25\n0.5\n0.15384615384615385\n0.25\n0.25\n0.2\n0.18181818181818182\n0.25\n0.25\n0.42857142857142855\n0.25\n0.5555555555555556\n0.25\n0.5\n0.25\n0.5\n0.25\n0.36363636363636365\n0.5\n0.25\n0.42857142857142855\n0.25\n0.15384615384615385\n0.5555555555555556\n0.2\n0.5\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 242
    }
   ],
   "source": [
    "######################cv contours#########\n",
    "# Invert floodfilled image\n",
    "im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "im2, contours_cv, hierarchy = cv2.findContours(im_floodfill_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "hierarchy = hierarchy[0]\n",
    "#[Next, Previous, First_Child, Parent]\n",
    "im_empty = np.ones((hImg, wImg,3), np.uint8) * 255\n",
    "i=0\n",
    "for cnt in contours_cv:\n",
    "    #contours that has at least two children\n",
    "    child1Idx = hierarchy[i][2]\n",
    "    hasChildren = child1Idx != -1 and  hierarchy[child1Idx][0] != -1\n",
    "    if(hasChildren):\n",
    "        child2Idx = hierarchy[child1Idx][0]\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    #this two children are close (letters)\n",
    "    #check area\n",
    "    if(hasChildren and h<=150 and w <=400):\n",
    "        #print((w*h)/area)\n",
    "        x1,y1,w1,h1 = cv2.boundingRect(contours_cv[child1Idx])\n",
    "        x2,y2,w2,h2 = cv2.boundingRect(contours_cv[child2Idx])\n",
    "        if(sqrt((x1-x2)**2+((y1-y2)**2)) <= 100):\n",
    "            cv2.drawContours(im_empty, contours_cv, i, (0,0,0), 1)\n",
    "    if(child1Idx != -1 and  hierarchy[child1Idx][0] == -1):\n",
    "        x1,y1,w1,h1 = cv2.boundingRect(contours_cv[child1Idx])\n",
    "        #print(w1/w)\n",
    "        if(w1/w >= 0.3):\n",
    "            cv2.drawContours(im_empty, contours_cv, i, (0,0,0), 1)\n",
    "    i+=1\n",
    "\n",
    "#cv2.drawContours(im_empty, contours_cv, -1, (0,0,0), 1)\n",
    "#print(hierarchy)\n",
    "cv2.imwrite(\"contoured.png\", im_empty)\n",
    "#########################################\n",
    "# Display images.\n",
    "cv2.imwrite(\"Thresholded_Image.png\", im_th)\n",
    "cv2.imwrite(\"Floodfilled_Image.png\", im_floodfill)\n",
    "cv2.imwrite(\"Inverted_Floodfilled_Image.png\", im_floodfill_inv)\n",
    "im_th2 = ((255 - im_th)/255).astype(int)\n",
    "im_ch = ((255 - im_empty[:,:,0])/255).astype(int)\n",
    "anded = im_th2 & im_ch\n",
    "cv2.imwrite(\"anded.png\", anded*255)\n",
    "\n",
    "#start flooding from corners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValid(imV,m, n, i, j):\n",
    "    #print(i<0 , i>= m , j<0 , j>= n , imV[j][i] == 0)\n",
    "    #print(i,j,m,n)\n",
    "    if (i<0 or i>= m or j<0 or j>= n or imV[j][i] == 0):\n",
    "        return False\n",
    "    return True\n",
    " \n",
    "# FloodFill function\n",
    "def floodFillBFS(screen,m, n, xImg, yImg):\n",
    "    queue = []\n",
    "     \n",
    "    # Append the position of starting\n",
    "    # pixel of the component\n",
    "    queue.append([xImg, yImg])\n",
    " \n",
    "    # Color the pixel with the new color\n",
    "    # if(screen[yImg][xImg]==0):\n",
    "    #     #print(\"hi\")\n",
    "    #     return\n",
    "    screen[yImg][xImg] = 0\n",
    " \n",
    "    # While the queue is not empty i.e. the\n",
    "    # whole component having prevC color\n",
    "    # is not colored with newC color\n",
    "    while queue:\n",
    "        # Dequeue the front node\n",
    "        currPixel = queue.pop() \n",
    "        posX = currPixel[0]\n",
    "        posY = currPixel[1]\n",
    "        # Check if the adjacent\n",
    "        # pixels are valid\n",
    "        if isValid(screen, m, n,posX + 1, posY):\n",
    "           # print(\"valid r\")\n",
    "            screen[posY][posX + 1] = 0\n",
    "            queue.append([posX + 1, posY])\n",
    "         \n",
    "        if isValid(screen, m, n,posX-1, posY):\n",
    "           # print(\"valid l\")\n",
    "            screen[posY][posX-1]= 0\n",
    "            queue.append([posX-1, posY])\n",
    "         \n",
    "        if isValid(screen, m, n, posX, posY + 1):\n",
    "           # print(\"valid d\")\n",
    "            screen[posY + 1][posX]= 0\n",
    "            queue.append([posX, posY + 1])\n",
    "         \n",
    "        if isValid(screen, m, n,posX, posY-1):\n",
    "            #print(\"valid u\")\n",
    "            screen[posY-1][posX]= 0\n",
    "            queue.append([posX, posY-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 810 is out of bounds for axis 0 with size 319",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_225363/3001438733.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mim_empty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mim_empty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mim_empty\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 810 is out of bounds for axis 0 with size 319"
     ]
    }
   ],
   "source": [
    "im_empty_2D=cv2.cvtColor(im_empty,cv2.COLOR_BGR2GRAY) \n",
    "for cnt in contours_closed:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    if w>20 and w<550 and h>5 and h<20:\n",
    "        i = int((2*x+w)/2) \n",
    "        i = i if i>0 else 0\n",
    "        j = y-1 if y>0 else 0\n",
    "        im_empty[j][i] = [0,0,255]\n",
    "        im_empty[y][x] = [0,255,0]\n",
    "        im_empty[y][x+w] = [0,255,0]\n",
    "        im_empty[y+h][x] = [0,255,0]\n",
    "        im_empty[y+h][x+w] = [0,255,0]\n",
    "        floodFillBFS(im_empty_2D,wImg,hImg, i,j)\n",
    "\n",
    "cv2.imwrite(\"contoured.png\", im_empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 189
    }
   ],
   "source": [
    "structureElm =  np.array((\n",
    "\t[1,1,1],\n",
    "\t[1,1,1],\n",
    "    [1,1,1]), dtype=\"int\")\n",
    "im_empty_2D = dilation(im_empty_2D, structureElm)\n",
    "\n",
    "cv2.imwrite(\"flooded.png\", im_empty_2D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}