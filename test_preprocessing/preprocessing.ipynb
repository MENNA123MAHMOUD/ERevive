{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9ca2a6701a14c49af8de80647c71f1770f3d09bf5589e6aad684858921f594a2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.filters import threshold_otsu\n",
    "import numpy as np\n",
    "from skimage.morphology import (erosion, dilation, opening, closing,  # noqa\n",
    "                                white_tophat)\n",
    "from skimage.measure import find_contours\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.draw import rectangle\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_imgs(img,contours,area):\n",
    "    i=0\n",
    "    big=0\n",
    "    for contour in contours:\n",
    "        x = contour[:,1]\n",
    "        y = contour[:,0]\n",
    "        [Xmin, Xmax, Ymin, Ymax] = [np.amin(x), np.amax(x), np.amin(y), np.amax(y)]\n",
    "        Ymin = int(Ymin)\n",
    "        Ymax = int(Ymax)\n",
    "        Xmax = int(Xmax)\n",
    "        Xmin = int(Xmin)\n",
    "        c = img[Ymin:Ymax,Xmin:Xmax]\n",
    "        if(area/20 < (Ymax-Ymin)*(Xmax-Xmin)):\n",
    "            big+=1\n",
    "        cv2.imwrite(\"contours/\"+str(i)+\".png\",c)\n",
    "        i+=1\n",
    "    return big\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_in = cv2.imread(\"er4.png\", cv2.IMREAD_GRAYSCALE)\n",
    "th, im_th = cv2.threshold(im_in, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "###################Remove words###############\n",
    "# structureElm =  np.array((\n",
    "# \t[1,1,1],\n",
    "# \t[1,1,1]), dtype=\"int\")\n",
    "# closed = closing(im_th, structureElm)\n",
    "\n",
    "# for i in range(30):\n",
    "#     closed = closing(closed, structureElm)\n",
    "\n",
    "# cv2.imwrite(\"closed.png\", closed)\n",
    "\n",
    "# im2, contours_cv, hierarchy = cv2.findContours(closed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# for cnt in contours_cv:\n",
    "#     x,y,w,h = cv2.boundingRect(cnt)\n",
    "#     if w>5 and w<300 and h>5 and h<30 :\n",
    "#         rr, cc = rectangle(start = (y,x), end = (y+h,x+w), shape=im_in.shape)\n",
    "#         im_th[rr.astype(int), cc.astype(int)] =  0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0,\n",
       " array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8),\n",
       " array([[1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1],\n",
       "        [1, 1, 1, ..., 1, 1, 1]], dtype=uint8),\n",
       " (0, 0, 0, 0))"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "# Mask used to flood filling.\n",
    "# Notice the size needs to be 2 pixels than the image.\n",
    "h, w = im_th.shape[:2]\n",
    "area = h*w\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    "\n",
    "im_floodfill = im_th.copy()\n",
    "##################Flood fill corners#####\n",
    "cv2.floodFill(im_floodfill, mask, (0,0), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (w-1,0), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (0,h-1), 255)\n",
    "cv2.floodFill(im_floodfill, mask, (w-1,h-1), 255)\n",
    "#cv2.floodFill(im_floodfill, mask, (int(w/2),int(h/2)), 255)\n",
    "# cv2.floodFill(im_floodfill, mask, (int(w*0.75),int(h/2)), 255) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 1\n",
      "1 1\n",
      "2 1\n",
      "3 1\n",
      "4 1\n",
      "5 1\n",
      "6 1\n",
      "7 1\n",
      "8 1\n",
      "9 1\n",
      "10 1\n",
      "11 1\n",
      "12 1\n",
      "13 1\n",
      "14 1\n",
      "15 1\n",
      "16 1\n",
      "17 1\n",
      "18 1\n",
      "19 1\n",
      "20 1\n",
      "21 1\n",
      "22 1\n",
      "23 1\n",
      "24 1\n",
      "25 1\n",
      "26 1\n",
      "27 2\n",
      "28 1\n",
      "29 1\n",
      "30 1\n",
      "31 1\n",
      "32 1\n",
      "33 1\n",
      "34 1\n",
      "35 1\n",
      "36 1\n",
      "37 1\n",
      "38 1\n",
      "39 1\n",
      "40 1\n",
      "41 1\n",
      "42 1\n",
      "43 4\n",
      "44 1\n",
      "45 1\n",
      "46 1\n",
      "47 1\n",
      "48 1\n",
      "49 1\n",
      "50 1\n",
      "51 1\n",
      "52 1\n",
      "53 1\n",
      "54 1\n",
      "55 1\n",
      "56 1\n",
      "57 1\n",
      "58 2\n",
      "59 1\n",
      "60 1\n",
      "61 1\n",
      "62 1\n",
      "63 1\n",
      "64 1\n",
      "65 1\n",
      "66 1\n",
      "67 1\n",
      "68 1\n",
      "69 1\n",
      "70 1\n",
      "71 1\n",
      "72 1\n",
      "73 1\n",
      "74 1\n",
      "75 1\n",
      "76 1\n",
      "77 1\n",
      "78 1\n",
      "79 1\n",
      "80 1\n",
      "81 1\n",
      "82 1\n",
      "83 1\n",
      "84 1\n",
      "85 1\n",
      "86 1\n",
      "87 1\n",
      "88 1\n",
      "89 1\n",
      "hi\n",
      "91 6\n",
      "92 6\n",
      "93 1\n",
      "94 2\n",
      "95 1\n",
      "96 1\n",
      "97 1\n",
      "98 1\n",
      "99 1\n",
      "100 1\n",
      "101 1\n",
      "102 2\n",
      "103 1\n",
      "104 1\n",
      "105 1\n",
      "106 1\n",
      "107 1\n",
      "108 1\n",
      "109 1\n",
      "110 1\n",
      "111 1\n",
      "112 1\n",
      "113 4\n",
      "114 1\n",
      "115 1\n",
      "116 1\n",
      "117 1\n",
      "118 1\n",
      "119 1\n",
      "120 1\n",
      "121 1\n",
      "122 1\n",
      "123 1\n",
      "124 1\n",
      "125 1\n",
      "126 2\n",
      "127 2\n",
      "128 1\n",
      "129 1\n",
      "130 1\n",
      "131 1\n",
      "132 1\n",
      "133 2\n",
      "134 1\n",
      "135 1\n",
      "136 1\n",
      "137 1\n",
      "138 1\n",
      "139 1\n",
      "140 1\n",
      "141 1\n",
      "142 1\n",
      "143 1\n",
      "144 1\n",
      "145 1\n",
      "146 3\n",
      "147 1\n",
      "148 6\n",
      "149 1\n",
      "150 1\n",
      "151 1\n",
      "152 1\n",
      "153 1\n",
      "154 1\n",
      "155 1\n",
      "156 1\n",
      "157 1\n",
      "158 1\n",
      "159 2\n",
      "160 1\n",
      "161 1\n",
      "162 1\n",
      "163 1\n",
      "164 4\n",
      "165 1\n",
      "166 1\n",
      "167 1\n",
      "168 1\n",
      "169 1\n",
      "170 1\n",
      "171 1\n",
      "172 1\n",
      "173 1\n",
      "174 1\n",
      "175 1\n",
      "176 1\n",
      "177 1\n",
      "178 4\n",
      "179 1\n",
      "180 1\n",
      "181 1\n",
      "182 1\n",
      "183 1\n",
      "184 1\n",
      "185 1\n",
      "186 1\n",
      "187 1\n",
      "188 1\n",
      "189 2\n",
      "190 1\n",
      "191 1\n",
      "192 1\n",
      "193 1\n",
      "194 1\n",
      "195 1\n",
      "196 1\n",
      "197 14\n",
      "198 1\n",
      "199 1\n",
      "200 2\n",
      "201 1\n",
      "202 1\n",
      "203 1\n",
      "204 1\n",
      "205 1\n",
      "206 1\n",
      "207 1\n",
      "208 1\n",
      "209 2\n",
      "210 1\n",
      "211 1\n",
      "212 1\n",
      "213 1\n",
      "214 1\n",
      "215 1\n",
      "216 1\n",
      "217 1\n",
      "218 1\n",
      "219 1\n",
      "220 5\n",
      "221 1\n",
      "222 1\n",
      "223 1\n",
      "224 1\n",
      "225 1\n",
      "226 1\n",
      "227 1\n",
      "228 2\n",
      "229 2\n",
      "230 1\n",
      "231 1\n",
      "232 1\n",
      "233 1\n",
      "234 1\n",
      "235 1\n",
      "236 1\n",
      "237 1\n",
      "238 1\n",
      "239 1\n",
      "240 1\n",
      "241 1\n",
      "242 1\n",
      "243 3\n",
      "244 1\n",
      "245 1\n",
      "246 1\n",
      "247 4\n",
      "248 1\n",
      "249 1\n",
      "250 1\n",
      "251 1\n",
      "252 1\n",
      "253 1\n",
      "254 1\n",
      "255 1\n",
      "256 1\n",
      "257 1\n",
      "258 1\n",
      "259 1\n",
      "260 1\n",
      "261 1\n",
      "262 4\n",
      "263 4\n",
      "264 4\n",
      "265 1\n",
      "266 1\n",
      "267 1\n",
      "268 1\n",
      "269 1\n",
      "270 1\n",
      "271 1\n",
      "272 1\n",
      "273 1\n",
      "274 1\n",
      "275 1\n",
      "276 1\n",
      "277 1\n",
      "278 1\n",
      "279 1\n",
      "280 1\n",
      "281 1\n",
      "282 1\n",
      "283 1\n",
      "284 1\n",
      "285 1\n",
      "286 2\n",
      "287 4\n",
      "288 1\n",
      "289 1\n",
      "290 1\n",
      "291 1\n",
      "292 1\n",
      "293 1\n",
      "294 2\n",
      "295 1\n",
      "296 1\n",
      "297 1\n",
      "298 1\n",
      "299 1\n",
      "300 1\n",
      "301 1\n",
      "302 1\n",
      "303 1\n",
      "304 1\n",
      "305 1\n",
      "306 1\n",
      "307 1\n",
      "308 1\n",
      "309 2\n",
      "310 10\n",
      "311 1\n",
      "312 1\n",
      "313 1\n",
      "314 1\n",
      "315 1\n",
      "316 1\n",
      "317 1\n",
      "318 1\n",
      "319 1\n",
      "320 1\n",
      "321 2\n",
      "322 4\n",
      "323 1\n",
      "324 1\n",
      "325 1\n",
      "326 1\n",
      "327 1\n",
      "328 1\n",
      "329 1\n",
      "330 1\n",
      "331 1\n",
      "332 5\n",
      "333 4\n",
      "334 4\n",
      "335 1\n",
      "336 1\n",
      "337 1\n",
      "338 1\n",
      "339 1\n",
      "340 1\n",
      "341 1\n",
      "342 1\n",
      "343 1\n",
      "344 1\n",
      "345 1\n",
      "346 1\n",
      "347 6\n",
      "348 1\n",
      "349 1\n",
      "350 1\n",
      "351 1\n",
      "352 2\n",
      "353 1\n",
      "354 1\n",
      "355 1\n",
      "356 5\n",
      "357 2\n",
      "358 1\n",
      "359 1\n",
      "360 1\n",
      "361 1\n",
      "362 1\n",
      "363 1\n",
      "364 1\n",
      "365 1\n",
      "366 3\n",
      "367 1\n",
      "368 1\n",
      "369 1\n",
      "370 1\n",
      "371 1\n",
      "372 1\n",
      "373 1\n",
      "374 1\n",
      "375 1\n",
      "376 1\n",
      "377 1\n",
      "378 1\n",
      "379 1\n",
      "380 1\n",
      "381 1\n",
      "382 1\n",
      "383 1\n",
      "384 1\n",
      "385 5\n",
      "386 1\n",
      "387 1\n",
      "388 1\n",
      "389 1\n",
      "390 1\n",
      "391 1\n",
      "392 1\n",
      "393 1\n",
      "394 1\n",
      "395 1\n",
      "396 1\n",
      "397 2\n",
      "398 1\n",
      "399 1\n",
      "400 1\n",
      "401 1\n",
      "402 1\n",
      "403 1\n",
      "404 1\n",
      "405 1\n",
      "406 1\n",
      "407 1\n",
      "408 1\n",
      "409 1\n",
      "410 2\n",
      "411 1\n",
      "412 1\n",
      "413 1\n",
      "414 1\n",
      "415 1\n",
      "416 1\n",
      "417 1\n",
      "418 1\n",
      "419 1\n",
      "420 1\n",
      "421 1\n",
      "422 1\n",
      "423 1\n",
      "424 4\n",
      "425 1\n",
      "426 1\n",
      "427 1\n",
      "428 1\n",
      "429 1\n",
      "430 5\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "######################cv contours#########\n",
    "# Invert floodfilled image\n",
    "im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    "im2, contours_cv, hierarchy = cv2.findContours(im_floodfill_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "im_empty = np.ones((h, w,3), np.uint8) * 255\n",
    "\n",
    "i=0\n",
    "for cnt in contours_cv:\n",
    "    x,y,w1,h1 = cv2.boundingRect(cnt)\n",
    "    contour_area = w1*h1\n",
    "    area_per = contour_area/area\n",
    "    # if(i==8):\n",
    "    im_temp = np.ones((h, w,3), np.uint8) * 255\n",
    "    cv2.drawContours(im_temp, contours_cv, i, (0,0,0), 1)\n",
    "    gray_img=cv2.cvtColor(im_temp,cv2.COLOR_BGR2GRAY) \n",
    "    gray_img = np.float32(gray_img)\n",
    "    corners = None\n",
    "    corners = cv2.goodFeaturesToTrack(gray_img, 0, 0.1, 20,useHarrisDetector=True)\n",
    "    #print(type(corners))\n",
    "    if(corners is None):\n",
    "        i+=1\n",
    "       # print(\"hi\")\n",
    "        continue\n",
    "    corners = np.int0(corners)\n",
    "    cornersCount = 0\n",
    "    for c in corners:\n",
    "        xc, yc = c.ravel()\n",
    "        if((xc-x)/w <= 0.1 or (x+w-xc)/w <=0.1 or (yc-y)/h <=0.1 or (y+h-yc)/h <=0.1):\n",
    "            cornersCount +=1\n",
    "            cv2.circle(im_empty, (xc, yc), 1, 255, -1)\n",
    "    #print(i,len(corners))\n",
    "    if(cornersCount>5):\n",
    "        i+=1\n",
    "        continue\n",
    "    cv2.drawContours(im_empty, contours_cv, i, (0,0,0), 1)\n",
    "    # cv2.imwrite(\"gray.png\", gray_img)\n",
    "        # break\n",
    "    i+=1\n",
    "#cv2.drawContours(im, contours_cv, -1, (0,0,0), 1)\n",
    "cv2.imwrite(\"contoured.png\", im_empty)\n",
    "#########################################\n",
    "# Display images.\n",
    "cv2.imwrite(\"Thresholded_Image.png\", im_th)\n",
    "cv2.imwrite(\"Floodfilled_Image.png\", im_floodfill)\n",
    "cv2.imwrite(\"Inverted_Floodfilled_Image.png\", im_floodfill_inv)\n",
    "#start flooding from corners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "kernel1 = np.array((\n",
    "    [0,0,0],\n",
    "\t[-1,1,-1],\n",
    "    [0,0,0]), dtype=\"int\")\n",
    "kernel2 = np.array((\n",
    "\t[0,-1,0],\n",
    "    [0,1,0],\n",
    "    [0,-1,0]), dtype=\"int\")\n",
    "kernel3 = np.array((\n",
    "\t[-1,0,0],\n",
    "    [0,1,0],\n",
    "    [0,0,-1]), dtype=\"int\")\n",
    "kernel4 = np.array((\n",
    "\t[0,0,-1],\n",
    "    [0,1,0],\n",
    "    [-1,0,0]), dtype=\"int\")\n",
    "kernel5 = np.array((\n",
    "\t[0,-1,0],\n",
    "    [-1,4,-1],\n",
    "    [0,-1,0]), dtype=\"int\")\n",
    "#only bar edges after floodfilling the image\n",
    "image_with_edges = cv2.filter2D(im_floodfill, -1, kernel1)\n",
    "image_with_edges += cv2.filter2D(im_floodfill, -1, kernel2)\n",
    "image_with_edges += cv2.filter2D(im_floodfill, -1, kernel3)\n",
    "image_with_edges += cv2.filter2D(im_floodfill, -1,kernel4)\n",
    "#by subtraction we get all step edges\n",
    "edges = cv2.filter2D(im_floodfill, -1, kernel5)\n",
    "\n",
    "edges_ored = cv2.bitwise_not(image_with_edges & im_floodfill)\n",
    "cv2.imwrite(\"edges.png\", image_with_edges)\n",
    "cv2.imwrite(\"edges2.png\", edges)\n",
    "cv2.imwrite(\"edges_ored.png\", edges_ored)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        corners = cv2.cornerHarris(gray_img,4,3,0.05)\n",
    "        ret, corners = cv2.threshold(corners,0.02*corners.max(),255,0)\n",
    "        corners = np.uint8(corners)\n",
    "        # find centroids\n",
    "        ret, labels, stats, centroids = cv2.connectedComponentsWithStats(corners)\n",
    "        # define the criteria to stop and refine the corners\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "        corners = cv2.cornerSubPix(gray_img,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
    "        # Now draw them\n",
    "        res = np.hstack((centroids,corners))\n",
    "        res = np.int0(res)\n",
    "        im_empty[res[:,1],res[:,0]]=[0,0,255]\n",
    "        im_empty[res[:,3],res[:,2]] = [0,255,0]\n",
    "        print(i,len(corners),res[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on built-in function goodFeaturesToTrack:\n\ngoodFeaturesToTrack(...)\n    goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance[, corners[, mask[, blockSize[, useHarrisDetector[, k]]]]]) -> corners\n    .   @brief Determines strong corners on an image.\n    .   \n    .   The function finds the most prominent corners in the image or in the specified image region, as\n    .   described in @cite Shi94\n    .   \n    .   -   Function calculates the corner quality measure at every source image pixel using the\n    .   #cornerMinEigenVal or #cornerHarris .\n    .   -   Function performs a non-maximum suppression (the local maximums in *3 x 3* neighborhood are\n    .   retained).\n    .   -   The corners with the minimal eigenvalue less than\n    .   \\f$\\texttt{qualityLevel} \\cdot \\max_{x,y} qualityMeasureMap(x,y)\\f$ are rejected.\n    .   -   The remaining corners are sorted by the quality measure in the descending order.\n    .   -   Function throws away each corner for which there is a stronger corner at a distance less than\n    .   maxDistance.\n    .   \n    .   The function can be used to initialize a point-based tracker of an object.\n    .   \n    .   @note If the function is called with different values A and B of the parameter qualityLevel , and\n    .   A \\> B, the vector of returned corners with qualityLevel=A will be the prefix of the output vector\n    .   with qualityLevel=B .\n    .   \n    .   @param image Input 8-bit or floating-point 32-bit, single-channel image.\n    .   @param corners Output vector of detected corners.\n    .   @param maxCorners Maximum number of corners to return. If there are more corners than are found,\n    .   the strongest of them is returned. `maxCorners <= 0` implies that no limit on the maximum is set\n    .   and all detected corners are returned.\n    .   @param qualityLevel Parameter characterizing the minimal accepted quality of image corners. The\n    .   parameter value is multiplied by the best corner quality measure, which is the minimal eigenvalue\n    .   (see #cornerMinEigenVal ) or the Harris function response (see #cornerHarris ). The corners with the\n    .   quality measure less than the product are rejected. For example, if the best corner has the\n    .   quality measure = 1500, and the qualityLevel=0.01 , then all the corners with the quality measure\n    .   less than 15 are rejected.\n    .   @param minDistance Minimum possible Euclidean distance between the returned corners.\n    .   @param mask Optional region of interest. If the image is not empty (it needs to have the type\n    .   CV_8UC1 and the same size as image ), it specifies the region in which the corners are detected.\n    .   @param blockSize Size of an average block for computing a derivative covariation matrix over each\n    .   pixel neighborhood. See cornerEigenValsAndVecs .\n    .   @param useHarrisDetector Parameter indicating whether to use a Harris detector (see #cornerHarris)\n    .   or #cornerMinEigenVal.\n    .   @param k Free parameter of the Harris detector.\n    .   \n    .   @sa  cornerMinEigenVal, cornerHarris, calcOpticalFlowPyrLK, estimateRigidTransform,\n    \n    \n    \n    goodFeaturesToTrack(image, maxCorners, qualityLevel, minDistance, mask, blockSize, gradientSize[, corners[, useHarrisDetector[, k]]]) -> corners\n    .\n\n"
     ]
    }
   ],
   "source": [
    "help(cv2.goodFeaturesToTrack)\n",
    "#TODO\n",
    "#instead of removing the words check for corners near border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}